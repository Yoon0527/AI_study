{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Chapter_4] Neural_Network_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtQi2OothnWW9+fP6w7JOG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoon0527/AI_study/blob/main/%5BChapter_4%5D_Neural_Network_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4. 신경망 학습\n",
        "학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 말한다. 특히 이번 장에서는 신경망이 학습할 수 있도록 해주는 지표인 '손실 함수(loss function)'에 대해 알아본다. 이 손실 함수의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표이다. 작게 만드는 방법 중 하나로 경사 하강법이 있음.\n",
        "\n",
        "신경망의 특징은 데이터를 보고 학습할 수 있다는 점이다. 이는 사람이 수작업으로 매개 변수 값을 설정하는 것이 아닌 가중치 매개 변수의 값을 데이터를 보고 자동으로 결정한다는 것이다. 즉, 데이터가 굉장히 중요하다.\n",
        "\n",
        "* 특징(Feature)\n",
        "  * 이미지에서 특징을 추출해 그 특징의 패턴을 기계학습 기술로 학습한다.\n",
        "  * 여기서 특징이란, 입력 데이터에서 중요한 데이터를 정확하게 추출할 수 있도록 설계된 변환기를 가리킨다.\n",
        "  * 이미지의 특징은 보통 SIFT, SURF, HOG와 같은 특징을 사용해 **벡터**로 기술하는데, 이런 특징을 사옹해 이미지 데이터를 벡터로 변환하고, 변환된 벡터를 가지고 지도 학습 방식의 대표 분류 기법인 SVM, KNN 등으로 학습할 수 있다.\n",
        "     * SIFT, SURF, HOG에 대한 자료: https://darkpgmr.tistory.com/116\n",
        "\n",
        "즉, 신경망은 사람이 개입하지 않고 이미지의 특징을 찾아 패턴을 학습한다. 그래서 신경망(딥러닝)을 종단간 기계학습(end-to-end machine learning)이라고도 한다. 데이터(입력)에서 목표한 결과(출력)를 사람의 개입 없이 얻는다는 뜻을 담고 있다.\n",
        "\n",
        "* 과대적합(Over Fitting)\n",
        "  * 기계학습은 데이터를 training data와 test data로 나누어 학습과 실험을 수행하는 것이 일반적이다. \n",
        "  * training data를 사용해 학습하면서 최적의 매개변수를 찾고, 그 다음 test data를 사용해 훈련한 모델의 실력을 평가한다.\n",
        "  * 두 데이터로 나누는 이유는 처음 본 이미지에서도 좋은 성능을 발휘하게 만들기 위해서이다. 나누지 않고 오로지 training data로만 학습한다면, 특정 데이터만 학습하게 되고, 한 데이터셋에만 지나치게 최적화되어 임의의 데이터의 패턴을 잘 발견하지 못하게되는 과대적합, 즉 오버피팅이 된다."
      ],
      "metadata": {
        "id": "1h1k5tUDyQGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실 함수\n",
        "신경망 학습에서는 현재의 상태를 '하나의 지표'로 표현한다. 이 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색하는 것이다. 신경망에서는 이 지표로 손실 함수를 사용한다. 손실 함수에도 종류가 있는데 일반적으로 '오차제곱합'과 '교차 엔트로피 오차'를 사용한다.\n",
        "\n",
        "* 오차제곱합(sum of squares for error, SSE)\n",
        "  * 각 원소의 출력(추정값)과 정답 레이블의 차를 제곱한 후, 그 총합을 구한다.\n",
        "  * 자세한 내용과 수식은 책 112페이지를 참고."
      ],
      "metadata": {
        "id": "NRLvpFmr1NCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차제곱합 구현해보기\n",
        "import numpy as np\n",
        "\n",
        "def sum_squares_error(y, t):\n",
        "  return 0.5 * np.sum((y-t)**2)\n",
        "\n",
        "# mnist 손글씨에서 숫자 2일 확률이 가장 높다고 추정\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]    # 정답 레이블, 원핫\n",
        "y_2 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]    # 여기서는 '2'일 확률이 가장 높다고 추정(0.6)\n",
        "print(sum_squares_error(np.array(y_2), np.array(t)))\n",
        "\n",
        "# 숫자 7일 확률이 가장 높다고 추정\n",
        "y_7 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y_7), np.array(t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK-bc8YbyPpD",
        "outputId": "e1f0d30b-a64b-4474-b172-0741419c8fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 코드로 봤을 때, 오차제곱합은 정답과 추정 결과와의 오차가 적을 수록 정답에 가깝다고 판단할 수 있다."
      ],
      "metadata": {
        "id": "IgPk8J583RCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 교차 엔트로피 오차\n",
        "  * 수식은 114페이지 참고.\n",
        "  * 정답일 때의 추정의 자연로그를 계산하는 수식이다.\n",
        "    * 정답 레이블은 원핫 인코딩 됐으므로 정답이 아닌 나머지는 모두 0이다. 그래서 log(y)와 곱해도 0이 되어 결과에 영향을 미치지 않는다.\n",
        "  * 다시 읽을 때마다 그래프와 설명을 같이 읽을 것."
      ],
      "metadata": {
        "id": "GptnByFu9UZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 엔트로피 오차 구현해보기\n",
        "def cross_entropy_error(y, t):    # y, t는 넘파이 배열이다.\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t * np.log(y + delta))\n",
        "\n",
        "# mnist 손글씨에서 숫자 2일 확률이 가장 높다고 추정\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]    # 정답 레이블, 원핫\n",
        "y_2 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]    # 여기서는 '2'일 확률이 가장 높다고 추정(0.6)\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n",
        "# 숫자 7일 확률이 가장 높다고 추정\n",
        "y_7 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(cross_entropy_error(np.array(y_7), np.array(t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMpTsk8_LJd",
        "outputId": "49c8223f-5dbf-4a10-cb78-0cd9e9f7f2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 예는 정답일 때의 출력이 0.6이고, 이때 교차 엔트로피 오차는 약 0.51이다.\n",
        "\n",
        "그 다음 정답일 때의 출력이 0.1일 때는 교차 엔트로피 오차가 2.3이다.\n",
        "\n",
        "즉, 결과(오차 값)가 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것이다.\n",
        "\n",
        ">**delta를 더해주는 이유?**<br> 아주 작은 값인 1e-7인 delta를 더해주는 이유는 np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 더 이상 계산을 진행할 수 없게되기 때문이다. **아주 작은 값을 더해서 절대 0이 될 수 없도록, 즉 마이너스 무한대가 발생하지 않도록 한 것이다.**"
      ],
      "metadata": {
        "id": "akkuKsg__m7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 미니배치 학습\n",
        "  * 기계학습에서는 훈련 데이터에 대한 손실 함수의 값을 구하고, 그 값을 최대한 줄여주는 매개변수를 찾아낸다.\n",
        "  * 이렇게 하려면 모든 훈련 데이터를 대상으로 손실 함수 값을 구해야 한다. 즉, 100개의 훈련 데이터가 있으면 그로부터 계산한 100개의 손실 함수 값들의 합을 지표로 삼는 것이다.\n",
        "  * 지금까지는 데이터 하나에 대한 손실 함수 값을 구했지만 이제 모든 학습 데이터에 대한 것을 구해야 한다.\n",
        "  * 데이터의 수가 많은 경우 데이터 일부를 추려 전체의 '근사치'로 이용할 수 있다.\n",
        "  * 신경망 학습에서도 훈련 데이터 중 일부만 골라 학습을 수행한다. \n",
        "  * 이 일부를 **미니배치**라고 한다. 예를 들어 60000개의 데이터 중 무작위로 100장을 뽑아 학습에 사용하는 것이다. 이런 학습 방법을 미니배치 학습이라고 한다."
      ],
      "metadata": {
        "id": "vDWICkz1BQva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 미니배치 구현해보기\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)   # 지정한 범위의 수 중에서 무작위로 원하는 개수만 꺼낸다.\n",
        "x_batch = x_train[batch_mask]\n",
        "y_batch = y_train[batch_mask]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7woCvCRSAKi5",
        "outputId": "30be6e0d-fcc2-4a42-b923-0ca28b543133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice(60000, 10)   # 60000 이하의 숫자 중 무작위로 10개 뽑는다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS1coYNsDdCc",
        "outputId": "22df101a-468e-4fa1-82db-59a963a6016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29586, 12056, 53180, 25271, 11821, 20006, 50927, 25933, 21479,\n",
              "       43189])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "무작위로 뽑은 수를 미니배치로 뽑아낼 데이터의 인덱스로 사용한다."
      ],
      "metadata": {
        "id": "v_i2re_OEdeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치용 교차 엔트로피 오차 구현해보기\n",
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "oElgnzXiEcLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y는 신경망의 출력, t는 정답 레이블이다. \n",
        "\n",
        "y가 1차원이라면, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape 함수로 데이터의 형상을 바꿔준다. 그리고 배치의 크기로 나눠 정규화하고 이미지 1장당 평균의 교차 엔트로피 오차를 계산한다."
      ],
      "metadata": {
        "id": "Sm1diQFZFNlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답 레이블이 원핫인코딩이 아니라 숫자 레이블로 주어졌을 때의 교차 엔트로피 오차 구현해보기\n",
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "mloEeaIUFgxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **왜 손실 함수를 설정하는가?**<br>신경망의 학습 지표로 '정확도'가 아닌 '손실 함수의 값'을 설정하는 이유는 신경망 학습에서의 **미분**의 역할에 주목해야 하는데, 자세한 내용은 119페이지를 볼 것. 읽기 전에 정확도와 손실 함수의 값 각각을 미분했을 때의 차이를 생각해보고 읽을 것.(반복적으로 읽어서 완벽하게 이해하자) "
      ],
      "metadata": {
        "id": "uxLgg_G8JiDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치 미분\n",
        "def numerical_diff(f, x):\n",
        "  h = 1e-4 #0.0001\n",
        "  return (f(x+h) - f(x-h)) / (2*h)"
      ],
      "metadata": {
        "id": "KmET3gvAY2oY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 식 4.5를 구현\n",
        "def function_1(x):\n",
        "  return 0.01*x**2 + 0.1*x"
      ],
      "metadata": {
        "id": "K1o-_EgsaCuB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = function_1(x)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zayjgGFoaCrU",
        "outputId": "b655b31d-b4b5-49fb-fd26-a4c8b201f1ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x=5, x=10일 때 이 함수의 미분을 계산해보자\n",
        "numerical_diff(function_1, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYvUxYOhaCpD",
        "outputId": "1b445892-e129-4ced-8c33-2a1b8e434880"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1999999999990898"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_diff(function_1, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z8Kv0c3aCmh",
        "outputId": "f4e9e870-25e1-4daa-877b-9b0f84a6a5d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2999999999986347"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 계산한 미분 값이 x에 대한 f(x)에 대한 변화량이다. 즉, 함수의 기울기에 해당한다. "
      ],
      "metadata": {
        "id": "tMRLptuUbLqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "편미분은 변수가 2개라는 점에 주의해야한다. "
      ],
      "metadata": {
        "id": "a1-l5MLLcDFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 편미분\n",
        "def function_2(x):\n",
        "  return np.sum(x**2)\n",
        "  # 또는 x[0]**2 + x[1]**2"
      ],
      "metadata": {
        "id": "1tyqaqR3aCkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 경사법(경사 하강법)\n",
        "> 이전 부분(미분)은 시간 날 때마다 책을 직접 읽는게 나을 것 같아서 코드와 코드에 대한 설명들 외에 이론 전부는 정리하지않음.\n",
        "\n",
        "기계학습 문제 대부분은 학습 단계에서 최적의 매개변수를 찾아낸다. 신경망 역시 최적의 매개변수(가중치와 편향)을 학습 시에 찾아야 한다. 여기에서 최적이란 손실 함수가 최솟값이 될 때의 매개변수 값이다. \n",
        "\n",
        "그러나 일반적인 문제의 손실 함수는 매우 복잡하다. 매개변수 공간이 광범위하여 어디가 최솟값이 되는 곳인지를 짐작할 수 없다. 이런 상황에서 기울기를 잘 이용해 함수의 최솟값(또는 가능한 작은 값)을 찾으려는 것이 경사법이다. "
      ],
      "metadata": {
        "id": "JxqyI5yTEnuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 편미분\n",
        "def function_tmp1(x0):\n",
        "  return x0*x0 + 4.0**2.0\n",
        "\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSuYwkFQY0AV",
        "outputId": "3982250b-e8aa-4eeb-f6ee-8e8fb0cf7642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def function_tmp2(x1):\n",
        "  return 3.0**2.0 + x1*x1\n",
        "\n",
        "numerical_diff(function_tmp2, 4.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67B0OhdGaKTx",
        "outputId": "7cb21330-5a02-421d-93a7-13ee331a8691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기\n",
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x) # x와 형상이 같은 배열 생성\n",
        "\n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]"
      ],
      "metadata": {
        "id": "8wJWVwBTaf6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}